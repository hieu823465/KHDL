{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "356ba172",
   "metadata": {},
   "source": [
    "***\n",
    "# Parse HTML to playlists.csv, users.csv, tracks.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea2324f",
   "metadata": {},
   "source": [
    "## Needed Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7f19ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import requests_cache\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import pandas as pd # Dùng để đọc và hiển thị file csv/tsv\n",
    "# YOUR CODE HERE (OPTION) \n",
    "import datetime\n",
    "# Nếu cần các thư viện khác thì bạn có thể import ở đây\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "import urllib.robotparser # Kiểm tra file robot.txt có được phép crawl không"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4c9d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_time = 1 # Đơn vị: giây"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1f4a21",
   "metadata": {},
   "source": [
    "## Collect Playlist\n",
    "\n",
    "*__collect_playlist__* func help us to collect playplists individually from existed url playlists to playlist.csv with a format of \"*playlist's name + list of track's name*\"  \n",
    "\n",
    "Playlist's name      : get the name of the main playlist  \n",
    "List of track's name : get list of tracks name according to current playlist.\n",
    "\n",
    "Wrriten by: *__Nguyễn Trung Hiếu__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e4555c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_playlist(playlist_url, playlist_file):\n",
    "    driver = webdriver.Chrome(executable_path=r'C:\\Users\\ASUS\\Source_ipynb\\chromedriver_win32\\chromedriver.exe')  \n",
    "    \n",
    "    with open(playlist_file,'w', encoding='utf-8') as fo_playlist:\n",
    "        with open(playlist_url,'r', encoding='utf-8') as fin:\n",
    "            \n",
    "            # column for each csv file\n",
    "            fo_playlist.write('playlists\\ttracks\\n')\n",
    "    \n",
    "            # run per url to get playlist title and trackID\n",
    "            for url_text in fin.readlines():\n",
    "                time.sleep(sleep_time)\n",
    "                \n",
    "                driver.get(url_text.strip())\n",
    "                html_text = driver.page_source\n",
    "                \n",
    "                soup = BeautifulSoup(html_text,'lxml')\n",
    "                \n",
    "                #get playlist title\n",
    "                title = soup.find('h1',class_='soundTitle__title').text.strip()\n",
    "                fo_playlist.write(title + \"\\t\")\n",
    "                \n",
    "\n",
    "                #get trackIDs\n",
    "                trackItem_title = soup.find_all('a',class_='trackItem__trackTitle')\n",
    "                listTrackId = ''\n",
    "               \n",
    "                \n",
    "                # get tracklist\n",
    "                for index in range(0,len(trackItem_title)):\n",
    "                        listTrackId += trackItem_title[index].text + \",\"     \n",
    "   \n",
    "                fo_playlist.write(listTrackId.rstrip(',') +\"\\n\")\n",
    "                sleep(random.randint(2,5))\n",
    "                            \n",
    "collect_playlist('playlist_urls_file.txt','playlists.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb44285",
   "metadata": {},
   "source": [
    "## Collect Track\n",
    "\n",
    "*__collect_track__* func help us to collect playplists individually from existed url track to tracks.csv with a format of \"*Tracks + Play-repeated + heart + comment*\"\n",
    "\n",
    "Tracks     : track's name  \n",
    "Play-reated: how many times has this track play repetitvely  \n",
    "Heart      : number of heart giving by user  \n",
    "Comment    : how many people comment on this track\n",
    "\n",
    "Wrriten by: *__Nguyễn Trung Hiếu__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675ba438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_track(playlist_url, playlist_file):\n",
    "    driver = webdriver.Chrome(executable_path=r'C:\\Users\\ASUS\\Source_ipynb\\chromedriver_win32\\chromedriver.exe')  \n",
    "    \n",
    "    with open(playlist_file,'w', encoding='utf-8') as fo_playlist:\n",
    "        with open(playlist_url,'r', encoding='utf-8') as fin:\n",
    "            \n",
    "            # column for each csv file\n",
    "            fo_playlist.write('tracks\\tplay-repeated\\theart\\tcomment\\n')\n",
    "    \n",
    "            # run per url to get playlist title and trackID\n",
    "            for url_text in fin.readlines():\n",
    "                time.sleep(sleep_time)\n",
    "                driver.get(url_text.strip())\n",
    "                sleep(random.randint(3,6))\n",
    "                html_text = driver.page_source\n",
    "                \n",
    "                soup = BeautifulSoup(html_text,'lxml')\n",
    "                \n",
    "                blockedTrack = soup.find('h1',class_='blockedTrackMessage')\n",
    "                    \n",
    "                if blockedTrack != None:\n",
    "                    continue\n",
    "            \n",
    "                \n",
    "                #get playlist title\n",
    "                title = soup.find('h1',{'class','soundTitle__title'})\n",
    "                \n",
    "                if title == None:\n",
    "                    continue\n",
    "                \n",
    "                fo_playlist.write(title.text.strip() + \"\\t\")\n",
    "                \n",
    "                #get Play\n",
    "                Time_Play = soup.find_all('span',class_='sc-ministats')\n",
    "                fo_playlist.write(Time_Play[0].text.split()[0].strip() + \"\\t\")\n",
    "                \n",
    "                #Get heart \n",
    "                heart = soup.find_all('li',class_='sc-ministats-item')\n",
    "                fo_playlist.write(heart[1]['title'].split()[0].strip() + \"\\t\")\n",
    "                \n",
    "                #Get comment\n",
    "                comment = soup.find('span', class_='commentsList__actualTitle')\n",
    "                fo_playlist.write(comment.text.split()[0].strip() + \"\\n\")\n",
    "                sleep(random.randint(7,10))\n",
    "                            \n",
    "collect_track('track_urls_file.txt','tracks.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bf4296",
   "metadata": {},
   "source": [
    "## Collect User\n",
    "\n",
    "*__collect_user__* func help us to collect playplists individually from existed url user to users.csv with a format of \"*user-name + Verified + Follower + Following + Track*\"\n",
    "\n",
    "User-name: user name  \n",
    "Verified : check whether that user is verified or not  \n",
    "Follower : number of followers\n",
    "Following: number of other user-name did this user name follow\n",
    "Track    : number of tracks has this user uploaded so far\n",
    "\n",
    "Wrriten by: __*Trần Xuân Phước*__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852a96da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_user(playlist_url, playlist_file):\n",
    "    driver = webdriver.Chrome(executable_path=r'C:\\Users\\ASUS\\Source_ipynb\\chromedriver_win32\\chromedriver.exe')  \n",
    "    \n",
    "    with open(playlist_file,'w', encoding='utf-8') as fo_playlist:\n",
    "        with open(playlist_url,'r', encoding='utf-8') as fin:\n",
    "            \n",
    "            # column for each csv file\n",
    "            fo_playlist.write('user-name\\tVerified\\tFollower\\tFollowing\\tTrack\\n')\n",
    "    \n",
    "            # run per url to get playlist title and trackID\n",
    "            for url_text in fin.readlines():\n",
    "                time.sleep(sleep_time)\n",
    "                \n",
    "                driver.get(url_text.strip())\n",
    "                sleep(random.randint(3,6))\n",
    "                html_text = driver.page_source\n",
    "                soup = BeautifulSoup(html_text,'lxml')\n",
    "                \n",
    "                #get user name \n",
    "                user_name = soup.find('h2',{'class','profileHeaderInfo__userName'})   \n",
    "                a = \"\"\n",
    "                is_verified = 0\n",
    "                for text in user_name.text.split():\n",
    "                    if \"Verified\" != text:\n",
    "                        a += text\n",
    "                    else:\n",
    "                        is_verified = 1\n",
    "                        fo_playlist.write(a + \"\\t1\\t\")\n",
    "                if is_verified == 0:\n",
    "                    fo_playlist.write(user_name.text.strip() + \"\\t0\\t\")\n",
    "                \n",
    "                #get Follower\n",
    "                info = soup.find_all('div',class_='infoStats__value')\n",
    "                fo_playlist.write(info[0].text.strip() + \"\\t\")\n",
    "                \n",
    "                #Get Following \n",
    "                fo_playlist.write(info[1].text.strip() + \"\\t\")\n",
    "                \n",
    "                #Get track\n",
    "                fo_playlist.write(info[2].text.strip() + \"\\n\")\n",
    "                sleep(random.randint(7,10))\n",
    "                            \n",
    "collect_user('user_urls_file.txt','users.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
